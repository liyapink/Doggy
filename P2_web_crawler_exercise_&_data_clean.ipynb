{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 安装辅助功能库\n> pip install pyquery"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests\nimport pandas as pd\nfrom pyquery import PyQuery\nimport time\nimport json",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 研究肖申克的救赎用户评论\nhttps://movie.douban.com/subject/1292052/comments\n> 研究用户评论的关键词词云\n提取用户名，点赞数，星级，评论\n\n- 打开网页\n- 使用chrome右键inspect\n- 点击Network并刷新"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "url = 'https://movie.douban.com/subject/1292052/comments'\nurl",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "'https://movie.douban.com/subject/1292052/comments'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Request Header(请求头)\n**使用inspect里的Network查看**\n- Accept:告诉服务器,浏览器能够处理的数据类型。(P575)\n- Accept-Charset:浏览器能显示的字符集。\n- Accept-Encoding:告诉服务器，客户机支持的数据压缩格式。\n- Aceept-Language:浏览器当前设置的语言。\n- Cache-Control：缓存控制，服务器通过控制浏览器要不要缓存数据\n- Connection:处理完这次请求，是断开连接还是保持连接\n- Cookie:客户机通过这个可以向服务器带数据\n- Host:访问的主机名\n- Upgrade-Insecure-Requests: 安全系数\n- **User-Agent:告诉服务器，客户机的软件环境**\n    - Response Headers响应头\n    - Connection:处理完这次请求后，是断开连接还是继续保持连接\n    - Content-Encoding:服务器通过这个头告诉浏览器数据的压缩格式\n    - Content-Length:服务器通过这个头告诉浏览器回送数据的长度 \n    - Content-Type:服务器通过这个头告诉浏览器回送数据的类型\n    - Date:当前时间值\n    - Server:服务器通过这个头告诉浏览器服务器的类型\n    - Vary:Accept-Encoding ——明确告知缓存服务器按照 Accept-Encoding 字段的内容，分别缓存不同的版本;\n    - X-Powered-By:服务器告知客户机网站是用何种语言或框架编写的。\n \n**对SEO重要的字段：Rerer Cookie user-agent ,Web前端会影响SEO，我们经常看到的网页不抓取、不收录、没排名和没流量有些是因为Web前端影响的。**"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 请完善以下header\nheader = {\n    \n}\nheader",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://movie.douban.com/subject/1292052/comments?start=20&limit=20&sort=new_score&status=P"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 请根据上述链接，完善以下的Query_string\nquery_string = {\n\n}\nquery_string",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### requests.get()\n- params: Query string\n- headers: request header\n\n### response类别：\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200\n- 200 OK\n- 404 Not Found"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 请使用requests.get()来获取相应的网页返回状态及内容\nresponse = requests.get(url, headers = header)\nresponse.text",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## CSS框架\nhttps://www.w3schools.com/css/exercise.asp\n- Tag\n- Class\n- Id\n- rel refer....\n\n**inspect里的Element查看架构**\n\n使用pyquery提取出html文件"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 使用PyQuery来提取网页内容结构\nquery = PyQuery(response.text)\nquery",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 获取用户名\nuser_id = \nuser_id",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 获取点赞数\nvotes = \nvotes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 获取星级\nrating = \nrating",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 获取评论\ncomments = \ncomments",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 创建Pandas表"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "columns = ['user_id', 'votes', 'rating', 'comments']\ncolumns",
      "execution_count": 3,
      "outputs": [
        {
          "data": {
            "text/plain": "['user_id', 'votes', 'rating', 'comments']"
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 将用户名、点赞数、星级、评论存入Dataframe\n",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 课后练习\nhttps://movie.douban.com/top250\n> 提取250部电影的信息，提取内容为电影，导演，主演，类型，上映时间，片长，评分"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# P2 Tips\n- 收集手头文件 twitter_archive_enhanced.csv，其中包含了一些主要的推特信息，是本次清洗的主要数据，其中的评分、地位和名字等数据是从 text 原文中提取的，但是提取的并不好，评分并不都是正确的，狗的名字和地位也有不正确的 。如果你想用评分、地位和名字进行分析和可视化，需要评估和清洗这些列。完成这些列的评估和清洗，你可以学到更加实用的技能。\n- 编程下载收集互联网文件：image-predictions.tsv，其中包含了推特图像预测信息，根据推特中的图片预测出狗狗种类；\n- 查询 API 收集额外推特信息 tweet_json.txt，如果你无法访问 Twitter 的话，可以直接读取项目可供下载的 tweet_json.txt 文件，从中提取所需数据。至少需要提取转发数（retweet_count）和喜欢数（favorite_count）这两列，如果你的分析中不需要用到其他列，则不需要收集其他列。如果提取了其他列只用于清洗，那么这样的清洗没有意义。\n\n## 项目重点要求\n- 可视化评估：每张收集的数据都显示在 Jupyter Notebook 中，以便进行可视化评估。 一旦显示出来，数据可以在外部应用程序（如 Excel，文本编辑器）中进行评估。\n- 编程评估：使用 pandas 的功能和/或方法来评估数据。\n- 学员能够检测到至少 八（8）个数据质量问题和两（2）个整洁度问题，包括待清理问题以满足项目要求。每一个问题用一到几句话记录下来。\n- 使用 Jupyter Notebook 中的 pandas 或 SQL 分析主数据集，并生成至少三（3）个独立的结论。\n- 在 Jupyter Notebook 中，使用 Python 绘图库或在 Tableau 中至少生成一（1）个标记的可视化对象。\n- 学员需要言简意赅地介绍他们的数据清理。 这一文件（wrangle_report.pdf）大约只需要300-600字。\n- 学员发现至少三（3）个结论，其中至少包含一个（1）可视化。这一文件（act_report.pdf）至少需要 250 个字。\n- 提交的文件包括如下：\n    - wrangle_act.ipynb\n    - wrangle_report.pdf\n    - act_report.pdf"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 加载 twitter-archive-enhanced.csv\n",
      "execution_count": 37,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 加载 image-predictions.tsv\nurl = \"https://raw.githubusercontent.com/udacity/new-dand-advanced-china/master/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/WeRateDogs%E9%A1%B9%E7%9B%AE/image-predictions.tsv\"\n",
      "execution_count": 35,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# 加载tweeter.txt并转换成dataframe\n",
      "execution_count": 36,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 数据质量评估方法\n数据质量评估体系主要参考以下指标：\n\n- 数据完整性\n- 数据准确性\n- 数据有效性\n- 数据时效性\n- 数据一致性\n\n## 数据完整性检测\n完整性，描述数据信息缺失的程度，是数据质量中最基础的一项评估标准。数据缺失的情况可以分为数据信息记录缺失和字段信息记录缺失。数据完整性检测的步骤是\n\n- 对于数据信息记录缺失的检测，可以通过对比源库上的表数据量和目的库上对应表的数据量来判断数据是否存在缺失。  \n    - 由于我给你们的就是你们所知的源库，本次无需检查本项\n- 对于字段信息记录缺失的检测，选择需要进行完整性检查的字段,计算该字段中空值数据的占比，通常来说表的主键及非空字段空值率为0%。空值率越小说明字段信息越完善，空值率越大说明字段信息缺失的越多。\n    - 我们每个数据集都需要去做，但是要注意，是选择**需要进行完整性检查的字段**的百分比\n\n## 数据准确性检测\n准确性，用于描述一个值与它所描述的客观事物的真实值之间的接近程度，通俗来说就是指**数据记录的信息是否存在异常或错误**。例如业务员在上报系统上填写客户信息时，手误输错了某一信息，造成了数据库里存在的信息与客观事实不一样。数据准确性的检测较为困难，一般情况下很难解决。在某些特定的情况下，例如性别，年龄，出生日期，籍贯等信息可以通过校验身份证号来检测，前提是确保身份证号码是正确的。\n> 俗称异常值\n\n## 数据有效性检测\n有效性，描述数据遵循预定的语法规则的程度，是否符合其定义，**比如数据的类型、格式、取值范围等**。数据有效性检测的步骤是用户选择需要进行有效性检测的字段，针对每个字段设定有效性规则。有效性规则包括类型有效、格式有效和取值有效等。类型有效检测字段数据的类型是否符合其定义，例如可以通过求和来判断是否是数值型，通过时间操作来判断是否是时间类型。格式有效性检测可以通过正则表达式来判断数据是否与其定义相符。取值有效检测则通过计算最大最小值来判断数据是否在有效的取值范围之内。\n> 即比如说常识人可以活0-110岁（我瞎说的），我们的数据集是讲骑自行车的，0-110岁的有效性就有待考证了。\n\n## 数据时效性检测\n时效性, 是指信息仅在一定时间段内对决策具有价值的属性。数据从生成到录入数据库存在一定的时间间隔，若该间隔较久，就可能导致分析得出的结论失去了借鉴意义。例如当天的交易数据生成后没有及时的录入数据库或者源库与目的库之间的同步延迟，则会导致统计结果和真实结果存在一定误差。\n\n## 数据一致性检测\n把待检测的表作为主表，首先用户确定一致性检测的主表字段，然后选择需要给定检测的从表和从表字段，设置好主表和从表之间的关联项,关联项可以是多个字段，但是关联项必须是拥有匹配值的相似字段。匹配关联之后检查主表和从表相同或者类似字段字段值是否一致。\n> 多表联合的时候需要重点注意"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "base_numbering": 1,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}